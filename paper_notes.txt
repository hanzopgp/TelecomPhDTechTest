PAPER 1 : Optimized preprocessing and Tiny ML for Attention State Classification

--------------------------------------------

Abstract :

EEG => study mental processes (attention, perception, emotion)
application => healthcare, HCI, education...
paper goal => new approach to classify mental state from EEG thanks to signal processing + ML
task => cognitive load task
results => high accuracy in classification > SOTA and computation efficiency

--------------------------------------------

Intro :

Attention => cognitive process that involves selection and prioritization of sensory info to process
Goal of classifying mental states => education / neurofeedback
EEG preprocessing => hard because non stationary / different from subject to subject etc...

Previous research :
SVM classifying 3 mental states => 91.72% acc (but train/test on a single subject, 7 chan)
SVM classifying drowsiness => 96.11% acc (but train/test on a single subject, 3 chan)
Some papers shows DL > ML

Contribution :
Optimize preprocessing to make it more suitable for Tiny ML (less comput, less engineers, less data)
Explore different compositions of labeled EEG data on the classif results
	Quantitative study on the parameters of feature extraction
	Models SVM/XGB/RF/2 NNs

--------------------------------------------

Method :
Pre-selection of the data
Feature extraction
Classification

Data : 
5 participants
25 hours of EEG
35-55 min per trial
3 labels 
	- focused but passive attention
	- unfocused or detached but awake
	- drowsy or on the verge of falling asleep
7 channels (F3, F4, Fz, C4, C4, Cz, Pz)
128Hz sampling rate
3 different ways of balancing data 
	- keep unbalanced one with a lot of drowsy state
	- take only 10 min of drowsy state for 33/33/33
	- take only 20 min of drowsy state for 50/50 between drowsy/non-drowsy
Channel selection check results for 7/6/5 channels...

Task :
Microsoft train simulator
10 first minutes => focused control of the simulated train (focused state)
10 next minutes => no control from the participant (defocused state)
End => relaxation (can close eyes etc...) (drowsy state)

Features extraction :
Analysis of frequency with fourier transform 
	- STFT window length w_L (how zoomed/dezoomed is the analysis of the graph)
	- STFT window shift w_S  (how much you move the window on the graph each time)
	- STFT window function w_F (reduce noise for easier analysis on the graph / smoothing)
Frequency binning (group frequencies in bin (size 0.5Hz) help ML to learn pattern 
Band restriction (set boundaries on which freq we want to analyse, here 0 to 18Hz)
Running average (smooth the spectrogram for overall trend, reduce noise)
Scaling
Train-test split
	- split-by-sample : split train/test for each subject
		- subject-specific : train/test on a single subject
		- common-subject : train/test on all subject at once
	- split-by-subject : train on a subject test on another
		- leave-one-out : 4 subject train 1 subject test

Classifiers :
RF
SVM 
XGB
NN
	- DNN_4 : 2 hidden 64 neurons
	- DNN_6 : DNN_4 + 2 hidden 128 neurons + 2 dropouts

--------------------------------------------

Experiments and results :

1. Data length study

7 Channels, same HP, leave-one-out, balanced accuracy
Compare accuracy for d_L = 10/20/max => 10/20 seems better than max
Compare recall for d_L = 10/20/max => 20/max seems better than 10
==> Shows that balancing is important use d_L = 20 for rest of experiment

2. STFT quantitative study

feature quality decrease with increasing w_L and w_S
use sample-sliding instead of window length ratio to avoid decrease in acc, best results w_S = 128, w_L = 4
acc +6%

3. Results of classification

test 3 split paradigm with optimal parameters
feature engineering effect : subject-specific paradigm, 96.7 -> 99.9 for best and 91.7 -> 99.8 for avg
channel selection : common-subject study paradigm, best channels : Fz, F3, Pz. 
	Random Forest > all with few channels
	SVM > all with lot of channels
models generalization : hard to generalize on feature extraction
	use leave-one-out paradigm best results with DNN_6

--------------------------------------------



--------------------------------------------

My own thoughts :

For the last part of the task, isn't there some better stimulis for the drowsy state ?

================================================================================

PAPER 2 : Towards On-device Learning on the Edge: Ways to Select Neurons to Update under a Budget Constraint

Goal is to develop better methods than raw back propagation for on-device learning

static strategy : evaluate neurons on generic dataset and the subnet will remain static for whole training
dynamic selection : it can change after every epochs (forward pass on whole dataset)

to improve on device learning : 
- find more efficient architcture (mobilenets, efficientnets...) / NAS (neural architecture search), quantization...
- perform sparse weight updates (loading each layers input tensor during gradient computation is costly) / use SU (sparse update is and optimized static selection of a subset of layers, problem is it needs evolutionary algorithm)

contribution : "we will present an approach embodying a different philosophy, challenging a static update graph allocation but rather identifying dynamically the partition of the model better to be updated."

goal is to expand SU and NEq selection techniques

--------------------------------------------

SU

1. sparse update fine tuning
2. mobilenet mcunet...
3. quantization
4. tiny training engine (transform training into binary code)

Lin et al tested with networks pre trained on image net and fine tune on Visual Wake Word classification, they froze the whole feature extraction part and only train the classification part

results :
- bias update works
- test each ratio for each layer update
- analysis of memory cost of each layers
- anaylsis of SU selection: if u add each improvements from above u get improvement
- they optimize bias update, layer update, cost with evolutionary algo, this algo returns a specific subset of layers ratios and bias depth to update = SU SCHEME

problem : 
- this is very expensive computation for the evo algo
- potential overfitting bc we train the sames neurons again and again (bc its static)

--------------------------------------------

NEq

goal is to reduce training time and cost without affecting perf
they select neuerons to freeze throughout training

maths part :
they compare the output of each neuron after receiving an output at a certain epochs t to the output at epochs t-1 (on validation set) using cosine similarity
the results informs us about the relationship betwwen input and output of the neuron
we can quantify the variation between epochs
equilibrium corresponds to this value being constant (it means the neurons has learn its i/o relationship
we can compute a velocity, equilibrium is when velocity is inferior than a certain positive epsilon (it just mean that the neuron isn't learning anymore epochs to epochs)

goal is to freeze the neurons at equilibrium to save computational cost

difference with SU : doesnt need prior knowledge of target dataset so we don't need to optimize layer bias and stuff
+ it is done dynamically at each epochs

problem : during the first epochs, almost all neurons velocities are high so memory cost is too high

--------------------------------------------

Budget-contraining approach

goal is to use NEq with maximum budget constraint
replace the epsilon threshold freezing condition with a budget for the whole neural network Bw (this is a number of updatable parameters). 
goal is to rank all velocities of all neurons
C_w_i is the number of parameters of the i-th neuron
B_w_j is the sum of the number of parameters of each neurons
problem is there is a bias for neurons with a higher number of parameters
to compensate we use v_i = v_i/c_w_i which is velocity-per-parameter

--------------------------------------------

Training algorithm

- pretrain model
- load model to target device
- static/dynamic neuron selection strategy
- need a train/valid dataset for the down-stream task (valid dataset is used to compute neuron velocities)

3 phase :
- select the sub-network to be updated for first epochs : can start with random selection in compliance with max budged or can use SU if possible
- train for one epoch
- evaluate velocities and select new sub-network
- iterate until a max epochs

--------------------------------------------

Experiments


























